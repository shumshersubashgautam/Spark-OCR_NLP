{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "253a2f32-44f0-48aa-a67e-5772f7858f32",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Spark-ocr visual doc classifier v2 preprocessing of RVL-CDIP dataset\n",
    "\n",
    "It is a sample of how to do preprocessing on databricks cluster with loading and saving data on s3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bffac31e-466e-4aab-b137-4f98431a3347",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "access_key = \"\"\n",
    "secret_key = \"\"\n",
    "encoded_secret_key = secret_key.replace(\"/\", \"%2F\")\n",
    "aws_bucket_name = \"\"\n",
    "mount_name = \"s3_dev\"\n",
    "\n",
    "try:\n",
    "  dbutils.fs.mount(\"s3a://%s:%s@%s\" % (access_key, encoded_secret_key, aws_bucket_name), \"/mnt/%s\" % mount_name)\n",
    "except:\n",
    "  dbutils.fs.unmount(\"/mnt/%s\" % mount_name)\n",
    "  dbutils.fs.mount(\"s3a://%s:%s@%s\" % (access_key, encoded_secret_key, aws_bucket_name), \"/mnt/%s\" % mount_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4a436543-0df1-4a07-9d61-04b0fa418a90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bash\n",
    "rm /dbfs/FileStore/johnsnowlabs/license.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c3ad4df6-c28c-42b1-b170-372204de927b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sh echo \"\" >> /dbfs/FileStore/johnsnowlabs/license.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "440afac6-859a-4544-af4a-18998bb45bf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat /dbfs/FileStore/johnsnowlabs/license.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf1e4c3d-9611-494f-9a79-a360930f7238",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "imagePath = \"dbfs:/mnt/s3_dev/ocr/datasets/rvl_cdip_full_/*.tif\"\n",
    "df = spark.read.format(\"binaryFile\").load(imagePath)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "427877e9-fff3-4476-a7bc-11a251e87dbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "label_names = {0: \"letter\",\n",
    "               1: \"form\",\n",
    "               2: \"email\",\n",
    "               3: \"handwritten\",\n",
    "               4: \"advertisement\",\n",
    "               5: \"scientific_report\",\n",
    "               6: \"scientific_publication\",\n",
    "               7: \"specification\",\n",
    "               8: \"file_folder\",\n",
    "               9: \"news_article\",\n",
    "               10: \"budget\",\n",
    "               11: \"invoice\",\n",
    "               12: \"presentation\",\n",
    "               13: \"questionnaire\",\n",
    "               14: \"resume\",\n",
    "               15: \"memo\"\n",
    "}\n",
    "\n",
    "files_labelled = {}\n",
    "with open(\"/dbfs/mnt/s3_dev/ocr/datasets/rvl_cdip_train_labels.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    for l in lines:\n",
    "      l_ = l.strip().split(\" \")\n",
    "      head, tail = os.path.split(l_[0])\n",
    "      #print(tail, label_names[int(l_[1])])\n",
    "      files_labelled[tail] = label_names[int(l_[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "242deae9-efc4-44e6-94ce-448d47d213ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------------+-------------------+------+--------------------+-------------+\n",
       "                path|   modificationTime|length|             content|    act_label|\n",
       "+--------------------+-------------------+------+--------------------+-------------+\n",
       "dbfs:/mnt/s3_dev/...|2022-07-28 17:21:50|962306|[49 49 2A 00 2C A...|advertisement|\n",
       "dbfs:/mnt/s3_dev/...|2022-07-29 10:06:47|934890|[49 49 2A 00 14 4...|         null|\n",
       "dbfs:/mnt/s3_dev/...|2022-07-27 15:51:57|909694|[49 49 2A 00 A8 D...|advertisement|\n",
       "dbfs:/mnt/s3_dev/...|2022-07-30 10:16:04|907192|[49 49 2A 00 E2 D...|         null|\n",
       "dbfs:/mnt/s3_dev/...|2022-07-29 20:41:01|868244|[49 49 2A 00 BE 3...|      invoice|\n",
       "+--------------------+-------------------+------+--------------------+-------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------------+-------------------+------+--------------------+-------------+\n|                path|   modificationTime|length|             content|    act_label|\n+--------------------+-------------------+------+--------------------+-------------+\n|dbfs:/mnt/s3_dev/...|2022-07-28 17:21:50|962306|[49 49 2A 00 2C A...|advertisement|\n|dbfs:/mnt/s3_dev/...|2022-07-29 10:06:47|934890|[49 49 2A 00 14 4...|         null|\n|dbfs:/mnt/s3_dev/...|2022-07-27 15:51:57|909694|[49 49 2A 00 A8 D...|advertisement|\n|dbfs:/mnt/s3_dev/...|2022-07-30 10:16:04|907192|[49 49 2A 00 E2 D...|         null|\n|dbfs:/mnt/s3_dev/...|2022-07-29 20:41:01|868244|[49 49 2A 00 BE 3...|      invoice|\n+--------------------+-------------------+------+--------------------+-------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [
        {
         "name": "df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "modificationTime",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "length",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "content",
            "nullable": true,
            "type": "binary"
           },
           {
            "metadata": {},
            "name": "act_label",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def get_label(fl):\n",
    "  head, fname = os.path.split(fl)\n",
    "  if fname in files_labelled:\n",
    "    return files_labelled[fname]\n",
    "  else:\n",
    "    print(\"File is missed:\", fname)\n",
    "    return None\n",
    "\n",
    "get_label_udf = udf(get_label)\n",
    "\n",
    "df = df.withColumn(\"act_label\", get_label_udf(\"path\"))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0b4f56cb-6752-404a-a600-181b1f6cf349",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=\"act_label\")\n",
    "df.select(\"path\", \"act_label\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a688640a-5b5b-4630-87db-cbd7ae0c423c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[20]: 18732</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[20]: 18732</div>",
       "datasetInfos": [
        {
         "name": "df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "modificationTime",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "length",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "content",
            "nullable": true,
            "type": "binary"
           },
           {
            "metadata": {},
            "name": "act_label",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.repartition(18732)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2ad0ed33-f322-4032-8ab8-a2c8e564cf9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sparkocr.transformers import *\n",
    "from sparkocr.enums import *\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "binary_to_image = BinaryToImage()\\\n",
    "    .setOutputCol(\"image\") \\\n",
    "    .setImageType(ImageType.TYPE_3BYTE_BGR)\n",
    "\n",
    "img_to_hocr = ImageToHocr()\\\n",
    "    .setInputCol(\"image\")\\\n",
    "    .setOutputCol(\"hocr\")\\\n",
    "    .setIgnoreResolution(False)\\\n",
    "    .setOcrParams([\"preserve_interword_spaces=0\"])\n",
    "\n",
    "tokenizer = HocrTokenizer()\\\n",
    "    .setInputCol(\"hocr\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# OCR pipeline\n",
    "pipeline1 = PipelineModel(stages=[\n",
    "    binary_to_image,\n",
    "    img_to_hocr,\n",
    "    tokenizer\n",
    "])\n",
    "\n",
    "df = pipeline1.transform(df).cache()\n",
    "df = df.withColumnRenamed(\"image\", \"orig_image\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "844bbf9c-1cd8-429f-bc03-593bc7b13c91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sparkocr.utils import get_vocabulary_dict\n",
    "\n",
    "vocab_file = \"/dbfs/mnt/s3_dev/ocr/test_models/LayoutLM.v2.voc.txt\"\n",
    "vocab = get_vocabulary_dict(vocab_file, \",\")\n",
    "\n",
    "doc_class = VisualDocumentClassifierV2() \\\n",
    "    .setInputCols([\"token\", \"orig_image\"]) \\\n",
    "    .setOutputCol(\"label\")\n",
    "doc_class.setVocabulary(vocab)\n",
    "\n",
    "result = doc_class.getPreprocessedDataset(\n",
    "  df,\n",
    "  [1,3,224,224]\n",
    "  ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "46781121-6463-4416-9253-1825cee14171",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result.select(\"path\", \"input_ids\", \"bbox\", \"image\", \"attention_mask\", \"token_type_ids\", \"act_label\").write.parquet(\"dbfs:/mnt/s3_dev/ocr/datasets/RVL-CDIP/processed_data\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Spark-ocr visual doc classifier v2 preprocessing of RVL-CDIP",
   "notebookOrigID": 602101501629399,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
